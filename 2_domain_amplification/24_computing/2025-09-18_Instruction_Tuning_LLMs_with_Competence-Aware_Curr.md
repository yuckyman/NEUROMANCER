---
type: note
category: 24-computing
created: 2025-09-18 12:09
modified: 2025-09-18 12:09
tags:
- instruction tuning
- LLM development
- curriculum learning
- competence-aware
- computer-vision
- machine-learning
- programming
- ai
- software
status: draft
source: inbox_processing
original_file: 20250918_114950_rss_Teaching_According_to_Talents__Instruction_Tuning_.txt
---


# Instruction Tuning LLMs with Competence-Aware Curriculum Learning

## summary
A proposed framework for efficient instruction tuning of large language models using curriculum learning strategies.

## content
RSS Feed: cs.AI updates on arXiv.org
Source: https://arxiv.org/rss/cs.AI
Link: https://arxiv.org/abs/2509.13790

Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning

arXiv:2509.13790v1 Announce Type: cross Abstract: Efficient instruction tuning aims to enhance the ultimate performance of large language models (LLMs) trained on a given instruction dataset. Curriculum learning as a typical data organization strategy has shown preliminary effectiveness in instruction tuning. However, current curriculum tuning methods suffer from the curriculum rigidity, since they rely solely on static heuristic difficulty metrics. These methods fail to adapt to the evolving capabilities of models during training, resulting in a fixed and potentially sub-optimal learning trajectory. To address the issue, Competence-Aware Multi-Perspective cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS offers several advantages: (1) Dynamic selection for sub-curriculum. (2) Competency-aware adjustment to the curriculum schedule. (3) Multiple difficulty-based scheduling. Extensive experiments prove the superior performance of CAMPUS, compared to other state-of...

## Scraped from https://arxiv.org/abs/2509.13790
[2509.13790] Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate &gt; cs &gt; arXiv:2509.13790 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search open search GO open navigation menu quick links Login Help Pages About --> Computer Science > Computation and Language arXiv:2509.13790 (cs) [Submitted on 17 Sep 2025] Title:Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning Authors:Yangning Li, Tingwei Lu, Yinghui Li, Yankai Chen, Wei-Chieh Huang, Wenhao Jiang, Hui Wang, Hai-Tao Zheng, Philip S.Yu View a PDF of the paper titled Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning, by Yangning Li and 8 other authors View PDF HTML (experimental) Abstract:Efficient instruction tuning aims to enhance the ultimate performance of large language models (LLMs) trained on a given instruction dataset. Curriculum learning as a typical data organization strategy has shown preliminary effectiveness in instruction tuning. However, current curriculum tuning methods suffer from the curriculum rigidity, since they rely solely on static heuristic difficulty metrics. These methods fail to adapt to the evolving capabilities of models during training, resulting in a fixed and potentially sub-optimal learning trajectory. To address the issue, Competence-Aware Multi-Perspective cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS offers several advantages: (1) Dynamic selection for sub-curriculum. (2) Competency-aware adjustment to the curriculum schedule. (3) Multiple difficulty-based scheduling. Extensive experiments prove the superior performance of CAMPUS...


## connections
- processed from phone shortcut
