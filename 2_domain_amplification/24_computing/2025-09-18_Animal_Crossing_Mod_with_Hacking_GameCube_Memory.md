---
type: note
category: 24-computing
created: 2025-09-18 11:54
modified: 2025-09-18 11:54
tags:
- programming
- retro-gaming
- replacing dialogues
- computer-vision
- machine-learning
- ai
- software
status: draft
source: inbox_processing
original_file: 20250918_114949_rss_I_Replaced_Animal_Crossing_s_Dialogue_with_a_Live_.txt
---


# Animal Crossing Mod with Hacking GameCube Memory

## summary
I replaced Animal Crossing's dialogue in the Game Cube using a Live LLM by Hacking GameCube Memory. The source code is available on GitHub.

## content
RSS Feed: Simon Willison's Weblog
Source: https://simonwillison.net/atom/everything/
Link: https://simonwillison.net/2025/Sep/10/animal-crossing-llm/#atom-everything

I Replaced Animal Crossing's Dialogue with a Live LLM by Hacking GameCube Memory

I Replaced Animal Crossing&#x27;s Dialogue with a Live LLM by Hacking GameCube Memory Brilliant retro-gaming project by Josh Fonseca, who figured out how to run 2002 Game Cube Animal Crossing in the Dolphin Emulator such that dialog with the characters was instead generated by an LLM. The key trick was running Python code that scanned the Game Cube memory every 10th of a second looking for instances of dialogue, then updated the memory in-place to inject new dialog. The source code is in vuciv/animal-crossing-llm-mod on GitHub. I dumped it (via gitingest, ~40,000 tokens) into Claude Opus 4.1 and asked the following: This interacts with Animal Crossing on the Game Cube. It uses an LLM to replace dialog in the game, but since an LLM takes a few seconds to run how does it spot when it should run a prompt and then pause the game while the prompt is running? Claude pointed me to the watch_dialogue() function which implements the polling loop. When it catches the dialogue screen opening it w...

## Scraped from https://simonwillison.net/atom/everything/
<?xml version="1.0" encoding="utf-8"?>
<feed xml:lang="en-us" xmlns="http://www.w3.org/2005/Atom"><title>Simon Willison's Weblog</title><link href="http://simonwillison.net/" rel="alternate"/><link href="http://simonwillison.net/atom/everything/" rel="self"/><id>http://simonwillison.net/</id><updated>2025-09-17T23:53:38+00:00</updated><author><name>Simon Willison</name></author><entry><title>Anthropic: A postmortem of three recent issues</title><link href="https://simonwillison.net/2025/Sep/17/anthropic-postmortem/#atom-everything" rel="alternate"/><published>2025-09-17T23:53:38+00:00</published><updated>2025-09-17T23:53:38+00:00</updated><id>https://simonwillison.net/2025/Sep/17/anthropic-postmortem/#atom-everything</id><summary type="html">
    
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues"&gt;Anthropic: A postmortem of three recent issues&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
Anthropic had a very bad month in terms of model reliability:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Between August and early September, three infrastructure bugs intermittently degraded Claude's response quality. We've now resolved these issues and want to explain what happened. [...]&lt;/p&gt;
&lt;p&gt;To state it plainly: We never reduce model quality due to demand, time of day, or server load. The problems our users reported were due to infrastructure bugs alone. [...]&lt;/p&gt;
&lt;p&gt;We don't typically share this level of technical detail about our infrastructure, but the scope and complexity of these issues justified a more comprehensive explanation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I'm really glad Anthropic are publishing this in so much detail. Their reputation for serving their models reliably has taken a notable hit.&lt;/p&gt;
&lt;p&gt;I hadn't appreciated the additional complexity caused by their mixture of different serving platforms:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We deploy Claude across multiple hardwar...


## Scraped from https://simonwillison.net/2025/Sep/10/animal-crossing-llm/#atom-everything
I Replaced Animal Crossing&#x27;s Dialogue with a Live LLM by Hacking GameCube Memory Simon Willisonâ€™s Weblog Subscribe I Replaced Animal Crossing&#x27;s Dialogue with a Live LLM by Hacking GameCube Memory (via) Brilliant retro-gaming project by Josh Fonseca, who figured out how to run 2002 Game Cube Animal Crossing in the Dolphin Emulator such that dialog with the characters was instead generated by an LLM. The key trick was running Python code that scanned the Game Cube memory every 10th of a second looking for instances of dialogue, then updated the memory in-place to inject new dialog. The source code is in vuciv/animal-crossing-llm-mod on GitHub. I dumped it (via gitingest, ~40,000 tokens) into Claude Opus 4.1 and asked the following: This interacts with Animal Crossing on the Game Cube. It uses an LLM to replace dialog in the game, but since an LLM takes a few seconds to run how does it spot when it should run a prompt and then pause the game while the prompt is running? Claude pointed me to the watch_dialogue() function which implements the polling loop. When it catches the dialogue screen opening it writes out this message instead: loading_text = ".&lt;Pause [0A]&gt;.&lt;Pause [0A]&gt;.&lt;Pause [0A]&gt;&lt;Press A&gt;&lt;Clear Text&gt;" Those &lt;Pause [0A]&gt; tokens cause the came to pause for a few moments before giving the user the option to &lt;Press A&gt; to continue. This gives time for the LLM prompt to execute and return new text which can then be written to the correct memory area for display. Hacker News commenters spotted some fun prompts in the source code, including this prompt to set the scene: You are a resident of a town run by Tom Nook. You are beginning to realize your mortgage is exploitative and the economy is unfair. Discuss this with the player and other villagers when appropriate. And this sequence of prompts that slowly raise the agitation of the villagers about their economic situation over time. The system actually uses two separa...


## connections
- processed from phone shortcut
