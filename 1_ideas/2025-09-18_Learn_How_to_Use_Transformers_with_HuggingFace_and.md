---
type: note
category: development, projects, ideas, reference, personal
created: 2025-09-18 11:54
modified: 2025-09-18 11:54
tags: ['transformers', 'spaCy', 'HuggingFace']
status: draft
source: inbox_processing
original_file: 20250918_114949_rss_Learn_How_to_Use_Transformers_with_HuggingFace_and.txt
---

# Learn How to Use Transformers with HuggingFace and SpaCy | Towards Data Science

## summary
Mastering NLP with spaCy: Part 4. The post Learn How to Use Transformers with HuggingFace and SpaCy appeared first on Towards Data Science.

## content
RSS Feed: Towards Data Science
Source: https://towardsdatascience.com/feed
Link: https://towardsdatascience.com/mastering-nlp-with-spacy-part-4/

Learn How to Use Transformers with HuggingFace and SpaCy

Mastering NLP with spaCy: Part 4 The post Learn How to Use Transformers with HuggingFace and SpaCy appeared first on Towards Data Science.

## Scraped from https://towardsdatascience.com/feed
<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Towards Data Science</title>
	<atom:link href="https://towardsdatascience.com/feed/" rel="self" type="application/rss+xml" />
	<link>https://towardsdatascience.com/</link>
	<description>Publish AI, ML &#38; data-science insights to a global community of data professionals.</description>
	<lastBuildDate>Thu, 18 Sep 2025 14:00:00 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.8.2</generator>

<image>
	<url>https://towardsdatascience.com/wp-content/uploads/2025/02/cropped-Favicon-32x32.png</url>
	<title>Towards Data Science</title>
	<link>https://towardsdatascience.com/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>From Python to JavaScript: A Playbook for Data Analytics in n8n with Code Node Examples</title>
		<link>https://towardsdatascience.com/from-python-to-javascript-a-playbook-for-data-analytics-in-n8n-with-code-node-examples/</link>
		
		<dc:creator><![CDATA[Samir Saci]]></dc:creator>
		<pubDate>Thu, 18 Sep 2025 15:30:00 +0000</pubDate>
				<category><![CDATA[Data Science]]></category>
		<category><![CDATA[Automation]]></category>
		<category><![CDATA[Data Analyitcs]]></category>
		<category><![CDATA[Javascript For Beginners]]></category>
		<category><![CDATA[n8n]]></category>
		<category><![CDATA[Supply Chain Analytics]]></category>
		<guid isPermaLink="false">https://towardsdatascience.com/?p=607179</guid>

					<description><![CDATA[<p>Learn the basics of JavaScript through tiny n8n Code node snippets for sales data anal...


## Scraped from https://towardsdatascience.com/mastering-nlp-with-spacy-part-4/
Learn How to Use Transformers with HuggingFace and SpaCy | Towards Data Science Publish AI, ML &amp; data-science insights to a global community of data professionals. Sign in Submit an Article LatestEditorâ€™s PicksDeep DivesNewsletter Write For TDS Toggle Mobile Navigation LinkedIn X Toggle Search Search Artificial Intelligence Learn How to Use Transformers with HuggingFace and SpaCy Mastering NLP with spaCy: Part 4 Marcello Politi Sep 15, 2025 7 min read Share Image src: https://unsplash.com/photos/purple-clouds-and-swirls-make-a-cosmic-display-DPcGXBCNL0c Introduction The Trasnformer is currently the the state of the art architecture for NLP and not only. Modern models like ChatGPT, Llama, and Gemma are based on this architecture introduced in 2017 in the Attention Is All You Need paper from Vaswani et al. In the previous article, we saw how to use spaCy to accomplish several tasks, and you might have noticed that we never had to train anything, but we leveraged spaCy capabilities, which are mainly rule-based approaches. SpaCy also offers to insert in the NLP pipeline trainable components or to use models off the shelf from the ðŸ¤— HuggingFace Hub, which is an online platform that provides open-source models for AI developers to use. So let&#8217;s learn how to use SpaCy with Hugging Face&#8217;s models! Why Transformers? Before transformers the SOTA architecture to create vector representations of words was word vectors techniques. A word vector is a dense representation of a word, which we can use to perform some mathematical calculation on it. For example, we can observe that two words that have a similar meaning also have similar vectors. The most famous techniques of this kind are GloVe and FastText. These methods, though, have introduced a big problem, a word is represented always by the same vector. But a word doesn&#8217;t always have the same meaning. For example: &#8220;She went to the bank to withdraw some money.&#8221; &#8220;He sat by the bank of the ri...


## connections
- processed from phone shortcut
